{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e30cfa-0106-48e7-9c36-9570ed48636f",
   "metadata": {},
   "source": [
    "## Cамостоятельная реализация решающего дерева  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ef2f9-af35-49fa-9200-4e95cd28973b",
   "metadata": {},
   "source": [
    "#### Определение дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad9bb34-c045-4e24-b5c5-622fb5ea66b8",
   "metadata": {},
   "source": [
    "Решающее дерево - **бинарное** дерево, в котором:\n",
    "1. Каждой *внутренней вершине* $v$ присвоен предикат предсказания: $B_v : \\mathbb{X} \\rightarrow \\{0, 1\\}$\n",
    "2. Каждой *листовой вершине* $v$ присвоен прогноз $C_v: \\mathbb{Y}$, где $\\mathbb{Y}$ - область значений таргета\n",
    "\n",
    "Каждый проход дерева начинается из корня. При прохождении очередной вершины мы двигаемся: *вправо*, если $B_v(x) = 1$; *влево*, если $B_v(x) = 0$. \n",
    "\n",
    "При достижении листа на объекте $x$, прогнозом для него будет являться $C_v$\n",
    "\n",
    "Особенности решающего дерева:\n",
    "1. Полученная функция кусочно-постоянная $\\rightarrow$ **не получится применить градиентные методы**\n",
    "2. Дерево **не может экстраполировать данные** за пределы уже имеющейся области значений признаков обучающей выборки\n",
    "3. Дереву свойственно **переобучение**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409d9db-851a-480c-85a8-74c0c9d5173c",
   "metadata": {},
   "source": [
    "#### Решающий пень"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da5e42-69fa-42ef-85e9-df71274f56b4",
   "metadata": {},
   "source": [
    "Дерево можно разбить на составляющие - решающие пни. Они будут представлять собой одну и вершину и два дочерних листа.\n",
    "\n",
    "Вершину мы будем разделять на листы при помощи предиката $B_{j, t}(x_i)$ . Качество разбиения мы будем оценивать при помощи критерия ветвления $Branch$.\n",
    "\n",
    "На листьях подзнее мы можем принять решение о необходимости дальнейшего разбиения -> построения еще одного решающего пня.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be38e5-e706-45b4-8cdb-ecb3d0bb4ed8",
   "metadata": {},
   "source": [
    "#### Сложность решающего пня"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dbf3a7-862d-4783-9518-ceb94a548f54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Пусть у нас есть матрица значений признаков $X \\in \\mathbb{R}^{D \\times N}$ и вектор таргетов $Y \\in \\mathbb{R}^N$.\n",
    "\n",
    "В основе вершины пня будет находится разделяющий предикат:\n",
    "$$B_{j, t}(x_i) = \\mathbb{I}\\left[x_{ij} \\le t\\right]$$\n",
    "Мы будем проходить не по самим значениям признаков, а по средним между значениями.\n",
    "$$x_i < t_i \\le x_{i+1}$$\n",
    "Поэтому мы пройдем всего по $N-1$ значению каждого признака.\n",
    "\n",
    "Тогда решение на пне примет вид:\n",
    "$$(j_{opt}, t_{opt}) = \\arg\\min_{j,t} L \\left( B_{j, t}, X, y \\right)$$\n",
    "\n",
    "Для того чтобы рассчитать $loss$, необходимо еще одного прохождение по $N$, в результате получим, что полный алгоритм решающего пня будет выполняться за $O(DN^2)$, где $D$ - кол-во признаков, $N$ - кол-во объектов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcdf79f-24d6-45c3-8da9-bc83e60fd11c",
   "metadata": {},
   "source": [
    "#### Главная проблема решающих деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c4266-691a-4f03-b251-a7f1ed1839e8",
   "metadata": {},
   "source": [
    "Запустив предложенный выше алгоритм рещающего пня рекурсивно, он будет выполняться до тех пор, пока полностью не выучит обучающую выборку -> переобучится.\n",
    "\n",
    "Если мы поставим задачу найти оптимальное решающее дерево при минимальном количестве разбиений, то решение такой задачи не сможем найти за полиномиальное время, т. к. она относится к np - полным задачам.\n",
    "\n",
    "Чтобы решить ситуацию в настоящий момент пользуются двумя способами:\n",
    "1. Жадный алгоритм\n",
    "2. Оптимизация исходного алгоритма ассимптотически и в константу раз"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31885f32-3702-4f43-8d0e-e221f2c00a92",
   "metadata": {},
   "source": [
    "#### Жадный алгоритм *построения* решающего дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379fe69-c61b-4e8e-9555-940c309d26fb",
   "metadata": {},
   "source": [
    "У нас уже есть матрица значений признаков $X$, определенная выше. Пусть $X_m \\subset X$ - множество всех объектов попавших в текущий лист.\n",
    "\n",
    "1. Создаем вершину $v$\n",
    "2. **Если**: выполнен ли критерий остановки $Stop(X_m)$, **то** останавливаемся и ставим ответ $Answ(X_m)$, объявив вершину листом.\n",
    "3. **Иначе**: Находим предикат $B_{j, t}$ имеющий лучшее разбиение на листы $X_m \\rightarrow X_l, X_r$. Максимизируя критерий ветвления $Branch(X_m)$\n",
    "4. Рекурсивно выполняем алгоритм для листьев $X_l, X_r$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e8292-6da5-405e-862a-3668c7274388",
   "metadata": {},
   "source": [
    "Подробнее разберем каждую функцию представленную в алгоритме:\n",
    "1. $Stop(X_m)$ - критерий остановки. Необходим для того, чтобы при построении решающего дерева мы могли остановиться и не переобучиться.\n",
    "2. $Answ(X_m)$ - функция вычисляющая ответ для листа, по попавшим в него объектам $X_m$. Может быть:\n",
    "   - Для задачи *классификации* ответ может быть: ***меткой самого частого класса*** или ***оценкой*** дискрет. ***распределения вероятностей классов*** для объектов в листе.\n",
    "   - Для задачи *регрессии*: ***средним, медианой или любой другой статистикой***\n",
    "   - Для любой задачи *простой моделью*: ***линейной функцией, синусойдой или любой другой функцией***\n",
    "3. $Stop(X_m)$ - критерий остановки при достижении определенных параметров дерево (про регуляризацию деревьев ниже)\n",
    "4. $Branch(X_m, j, t)$ - критерий ветвления"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3502a-6a76-411d-9e92-c9b3eba3b999",
   "metadata": {},
   "source": [
    "##### Подробнее про критерий ветвления"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a8bad-6467-4393-9925-65c9b60c02f1",
   "metadata": {},
   "source": [
    "Ответы дерева можем закодировать как: \n",
    "- $\\bar{c} \\in \\mathbb{R}^k$ для регрессии и классификации\n",
    "- $\\bar{c} = (c_1, ..., c_k) \\in \\mathbb{R}: \\sum_i \\bar{c} = 1$ для дискретного распределения вероятностей классов\n",
    "\n",
    "Предположим что задана функция потерь $L(y_i, c)$. *В момент поиска оптимального разделения* $X_m = X_l \\cup X_r$, мы можем *вычислить* для $X_m$ *константный таргет* $c$ (предикт дерева, если бы вершина была терминальной) и связанный с ним значение ф-ии потерь $L$. А именно - константа $c$ должна минимизировать среднее качество $L$.\n",
    "$$\\frac{1}{|X_m|} \\sum_{(x_i, y_i) \\in X_m} L(y_i, c)$$\n",
    "\n",
    "Тогда оптимальное значение:\n",
    "$$H(X_m) = \\min_{c \\in Y} \\frac{1}{|X_m|} \\sum_{(x_i, y_i) \\in X_m} L(y_i, c)$$\n",
    "\n",
    "$H(X_m)$ - называется ***неоднородностью (impurity)***, чем она ниже, тем предикт дерева ближе к *некоторому константному значению*.\n",
    "\n",
    "Таким же образом можно вычислить информативность всего решающего пня:\n",
    "1. $X_l$ - объекты попавшие в левый лист\n",
    "2. $X_r$ - объекты попавшие в правый лист\n",
    "3. $c_l$, $c_r$ - константы предсказаний в каждом листе для определенного $B_{j, t}(X_m)$\n",
    "\n",
    "Фукнция потерь всего пня:\n",
    "$$\\frac{1}{|X_m|} \\left( \\sum_{(x_i, y_i) \\in X_l} L(y_i, c_l) + \\sum_{(x_i, y_i) \\in X_r} L(y_i, c_r) \\right)$$\n",
    "\n",
    "Связать это с информативностью:\n",
    "$$ \\frac{1}{|X_m|} \\left( \\frac{|X_l|}{|X_l|} \\sum_{(x_i, y_i) \\in X_l} L(y_i, c_l) + \\frac{|X_r|}{|X_r|} \\sum_{(x_i, y_i) \\in X_r} L(y_i, c_r) \\right) = $$\n",
    "$$ = \\frac{|X_l|}{|X_m|} H(X_l) + \\frac{|X_r|}{|X_m|} H(X_r) $$\n",
    "\n",
    "Чтобы получить качество разбиения мы найдем разницу информативностей вершины и получившихся листьев:\n",
    "$$Branch(X_m, j, t) = |X_m| * H(X_m) - |X_l| * H(X_l) - |X_r| * H(X_r)$$\n",
    "\n",
    "\n",
    "Функция потерь выбирается под конкретную задачу, подробнее про выбранные функции будет при их реализации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989d5af-407c-4db7-8617-7d1d5155e498",
   "metadata": {},
   "source": [
    "#### Регуляризация решающих деревьев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8da2d1-6867-4114-a213-1412557aae6f",
   "metadata": {},
   "source": [
    "Так как дерево обязательно переобучится, если его не ограничить, то необходимо упомянуть о методах регуляризации деревьев:\n",
    "1. Ограничения по максимальной глубине\n",
    "2. Ограничения на минимальное количество объектов в листе\n",
    "3. Ограничение на максимальное количество листьев в дереве\n",
    "4. Требование, чтобы функционал качества при делении текущей подвыборки на две улучшался не менее чем на $s\\%$\n",
    "\n",
    "Перечисленные действия возможно выполнить на разных этапах действия алгоритма:\n",
    "- Pre-pruning: В процессе построения дерева при достижении критерия остановки\n",
    "- Post-pruning: После построения дерева, удалить некоторые вершины так, чтобы качество упало не сильно. Проверяя качество на val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1888b2-4edd-4d0b-8403-c5f6f1e0c744",
   "metadata": {},
   "source": [
    "#### Функции потерь: классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3fb2a0-6b87-433d-b5c8-be85d1c58e0c",
   "metadata": {},
   "source": [
    "##### Gini (Джини)\n",
    "\n",
    "Пусть предсказание модели - распределение вероятности классов: $\\bar{c} = (c_1, ..., c_k); \\sum_{i=1}^k c_i = 1$\n",
    "\n",
    "Тогда посчитаем *Brier score* на вероятностях классов при получившемся разбиении.\n",
    "$$BS(c) = \\frac{1}{N} \\sum_{i=1}^k \\left( c_k - \\mathbb{I} \\left[ y_i = k \\right] \\right)^2$$\n",
    "\n",
    "BS - при идеальном предсказании имеет значение. Чем меньше разница между предсказанным классом и вероятностью, тем ниже метрика.\n",
    "\n",
    "Следовательно функция неоднородности будет иметь вид минимизации функционала по каждому из классу\n",
    "\n",
    "$$H(X_m)= \\min_{\\sum_k c_k = 1} \\frac{1}{X_m} \\sum_{(x_i, y_i) \\in X_m} \\sum_{k=1}^K \\left( c_k - \\mathbb{I} \\left[ y_i = k \\right] \\right)^2$$\n",
    "\n",
    "Логично, что наименьшее зачение метрики достигается на $c$ состоящем из выборочных оценок частот классов в подвыборке $X_m$: $(p_1, ..., p_k), p_i = \\frac{1}{|X_m|} \\sum_i \\mathbb{I} \\left[ y_i = k \\right]$.\n",
    "\n",
    "Если подставить вектор выборочых оценок частот классов в форулу неоднородности, то получится свести задачу к следующему виду:\n",
    "$$H(X_m) = \\sum_{k=1}^K p_k (1 - p_k)$$\n",
    "\n",
    "Критерий Джини допускает следующую интерпретацию:\n",
    "\n",
    "$H(X_m)$ равно математическому ожиданию числа неправильных ответов, если мы будем присваивать им случайные метки классов согласно дискретному распределению заданному $(p_1, ..., p_k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c067e0-0711-43c8-b2f8-ddc269ddf5ee",
   "metadata": {},
   "source": [
    "#### Реализация класса обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86359b53-056a-4003-9cdf-e02db6e2147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99275886-fc78-49c8-bd4e-31753c49ca0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfDecisionTreeClassifier():\n",
    "    '''\n",
    "    Decision Tree Classifier\n",
    "    \n",
    "    Criterion: Gini, LogLoss, Entropy\n",
    "\n",
    "    Regularization presented with:\n",
    "    - Max depth of tree\n",
    "    - Min_leaf_samples of tree\n",
    "    \n",
    "    The decisive stump predicate is loking best split on all features all values\n",
    "    So to optimize all calculations we will use PyTorch and GPU\n",
    "    '''\n",
    "    def __init__(self, device: str, criterion: str = 'gini', max_depth: int | None = None, min_leaf_samples: int | None = 1):\n",
    "        assert criterion in ('gini', 'entropy', 'log')\n",
    "\n",
    "        self.device = device\n",
    "        \n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_leaf_samples = min_leaf_samples\n",
    "        self.K = None\n",
    "        \n",
    "        self.__thresholds = []\n",
    "        self.__features = []\n",
    "        self.__impurity_list = []\n",
    "        self.__is_leaf = []\n",
    "        self.__split = []\n",
    "\n",
    "        self.__all_lists = [\n",
    "            self.__thresholds,\n",
    "            self.__features,\n",
    "            self.__impurity_list,\n",
    "            self.__is_leaf,\n",
    "            self.__split\n",
    "        ]\n",
    "        \n",
    "        self.N = 0\n",
    "        self.D = 0\n",
    "\n",
    "    def __get_childerns_idxs(self, cur_idx: int) -> tuple[int, int]:\n",
    "        return (2 * cur_idx + 1, 2 * cur_idx + 2)\n",
    "    \n",
    "    def __extend_lists(self, cur_idx: int) -> None:\n",
    "        _, r_idx = self.__get_childerns_idxs(cur_idx)\n",
    "        \n",
    "        for i in range(len(self.__all_lists)):\n",
    "            if len(self.__all_lists[i]) < r_idx:\n",
    "                self.__all_lists[i].extend([None] * (r_idx - len(self.__all_lists[i])))\n",
    "            \n",
    "    def __stop(self):\n",
    "        pass\n",
    "\n",
    "    def _gini_loss(self, indices: torch.LongTensor) -> float:\n",
    "        counts = torch.bincount(self.y[indices, minlength=self.K)\n",
    "        probs = counts / indicies.shape[0]\n",
    "        probs\n",
    "\n",
    "    def _log_loss(self, indices: torch.LongTensor) -> float:\n",
    "        pass\n",
    "    \n",
    "    def _entropy_loss(self, indices: torch.LongTensor) -> float:\n",
    "        pass\n",
    "        \n",
    "    def __impurity(self, indices: torch.LongTensor) -> float:\n",
    "        loss_function = getattr(self, f'_{self.criterion}_loss')\n",
    "        return loss_function(indices)\n",
    "        \n",
    "    ## Recursive\n",
    "    def __split_node(self, cur_idx: int) -> None:\n",
    "        if self.__stop():\n",
    "            self.__is_leaf[cur_idx] = True\n",
    "            return\n",
    "        \n",
    "        best_branch_score = -float('inf') # Dict for all?\n",
    "        best_feature_idx = None\n",
    "        best_threshold = None\n",
    "        best_Xr_idxs = None\n",
    "        best_Xl_idxs = None\n",
    "        best_Hr = None\n",
    "        best_Hl = None\n",
    "        flag = False\n",
    "\n",
    "        for feature_idx in range(self.D):\n",
    "            sorted_vals, indices = torch.sort(self.X[:,feature_idx])\n",
    "            \n",
    "            prev_val = None\n",
    "            \n",
    "            # print('---' * 10)\n",
    "            # print('feature_idx', feature_idx)\n",
    "\n",
    "            len_Xm = sum(self.__split[cur_idx])\n",
    "            Hm = self.__impurity_list[cur_idx]            \n",
    "                 \n",
    "            for idx in range(0, self.N - 1):\n",
    "                \n",
    "                cur_val = sorted_vals[idx]\n",
    "                if cur_val == prev_val:\n",
    "                    continue\n",
    "                \n",
    "                threshold = (self.X[indices[idx], feature_idx] + self.X[indices[idx + 1], feature_idx]) / 2\n",
    "                \n",
    "                Xr_idxs = indices[:idx + 1]\n",
    "                Xl_idxs = indices[idx + 1:]\n",
    "\n",
    "                Hr = self.__impurity(self.X[Xr_idxs, feature_idx]) # Hr = H(Xr)\n",
    "                Hl = self.__impurity(self.X[Xl_idxs, feature_idx]) # Hl = H(Xl)\n",
    "\n",
    "                branch_score = len_Xm * Hm - Xl_idxs.shape()[0] * Hl - Xr_idxs.shape()[0] * Hr\n",
    "\n",
    "                if branch_score < best_branch_score:\n",
    "                    best_branch_score = branch_score\n",
    "                    best_feature_idx = feature_idx\n",
    "                    best_threshold = threshold\n",
    "                    best_Xr_idxs = Xr_idxs\n",
    "                    best_Xl_idxs = Xl_idxs\n",
    "                    best_Hr = Hr\n",
    "                    best_Hl = Hl                   \n",
    "                    flag = True\n",
    "                \n",
    "                prev_val = cur_val\n",
    "         \n",
    "                # print('idx: ', idx)\n",
    "                # print('threshold: ', threshold.item())\n",
    "                # print('Xl: ', Xl)\n",
    "                # print('Xr: ', Xr)\n",
    "        \n",
    "        if not(flag):\n",
    "            self.__is_leaf[cur_idx] = True\n",
    "            return\n",
    "\n",
    "        ## заполнить массивы\n",
    "        self.__extend_lists(cur_idx)\n",
    "        self.__thresholds[cur_idx] = best_threshold\n",
    "        self.__features[cur_idx] = best_feature_idx\n",
    "        self.__is_leaf[cur_idx] = False\n",
    "        \n",
    "        r_idx, l_idx = self.__get_childerns_idxs(cur_idx)\n",
    "        \n",
    "        self.__impurity_list[r_idx] = best_Hr \n",
    "        mask_r = torch.zeros(self.N, dtype=torch.bool, device=self.device)\n",
    "        mask_r[best_Xr_idxs] = True\n",
    "        self.__split[r_idx] = mask_r\n",
    "\n",
    "        self.__impurity_list[l_idx] = best_Hl \n",
    "        mask_l = torch.zeros(self.N, dtype=torch.bool, device=self.device)\n",
    "        mask_l[best_Xl_idxs] = True\n",
    "        self.__split[l_idx] = mask_l\n",
    "\n",
    "        ## вызвать рекурсивно на листах\n",
    "        self.__split_node(r_idx)\n",
    "        self.__split_node(l_idx)         \n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        assert X.shape[0] == y.shape[0], 'N dimension of X and y must be equal'\n",
    "        \n",
    "        self.X = torch.tensor(X, device=self.device)\n",
    "        self.y = torch.tensor(y, device=self.device)\n",
    "        \n",
    "        self.N = X.shape[0]\n",
    "        self.D = X.shape[1]\n",
    "\n",
    "        self.K = torch.unique(self.y)\n",
    "        \n",
    "        self.__extend_lists(0)\n",
    "        self.__impurity_list[0] = self.__impurity(X)\n",
    "        self.__split_node(0)\n",
    "        \n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aa94746-5b7f-4f0c-b37e-4bdf32003b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "[[0.24090958 0.42381796]\n",
      " [0.31356269 0.5104263 ]\n",
      " [0.78834808 0.52572796]\n",
      " [0.84516266 0.62038314]\n",
      " [0.9372263  0.91506107]]\n",
      "<bound method SelfDecisionTreeClassifier._gini_loss of <__main__.SelfDecisionTreeClassifier object at 0x000001C562929AF0>>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m random_array = np.random.rand(\u001b[32m5\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(np.sort(random_array, axis=\u001b[32m0\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mSelfDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 171\u001b[39m, in \u001b[36mSelfDecisionTreeClassifier.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28mself\u001b[39m.__extend_lists(\u001b[32m0\u001b[39m)\n\u001b[32m    170\u001b[39m \u001b[38;5;28mself\u001b[39m.__impurity_list[\u001b[32m0\u001b[39m] = \u001b[38;5;28mself\u001b[39m.__impurity(X)\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__split_node\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mSelfDecisionTreeClassifier.__split_node\u001b[39m\u001b[34m(self, cur_idx)\u001b[39m\n\u001b[32m     88\u001b[39m prev_val = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# print('---' * 10)\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# print('feature_idx', feature_idx)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m len_Xm = \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__split\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcur_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m Hm = \u001b[38;5;28mself\u001b[39m.__impurity_list[cur_idx]\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m.N - \u001b[32m1\u001b[39m):\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)\n",
    "random_array = np.random.rand(5, 2)\n",
    "print(np.sort(random_array, axis=0))\n",
    "SelfDecisionTreeClassifier(device).fit(random_array, np.array([0, 1, 1, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42f5d56f-d14d-4146-997b-f67a1cdea8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arr = torch.tensor([0, 1, 1, 0, 1])\n",
    "test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7eaaac67-91d3-406d-922f-09acbe81bfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cumsum(test_arr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04d3ff3f-7e7b-475e-9c5d-f2f54b82d23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4000, 0.6000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = torch.bincount(test_arr, minlength=test_arr.unique().shape[0])\n",
    "print(counts)\n",
    "probs = counts / test_arr.shape[0]\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7e6ea-d00a-4e32-9ee2-3ff214f4869e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
